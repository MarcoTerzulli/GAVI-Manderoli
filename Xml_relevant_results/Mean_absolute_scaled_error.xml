<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.35.0-wmf.31</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="446" case="first-letter">Education Program</namespace>
      <namespace key="447" case="first-letter">Education Program talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Mean absolute scaled error</title>
    <ns>0</ns>
    <id>31360933</id>
    <revision>
      <id>948405543</id>
      <parentid>930430117</parentid>
      <timestamp>2020-03-31T21:36:13Z</timestamp>
      <contributor>
        <username>Me, Myself, and I are Here</username>
        <id>17619453</id>
      </contributor>
      <minor/>
      <comment>cap, rm space, adjust bold</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text bytes="7670" xml:space="preserve">In [[statistics]], the '''mean absolute scaled error''' ('''MASE''') is a measure of the [[accuracy]] of [[forecasting|forecast]]s. It is the mean absolute error of the forecast values, divided by the mean absolute error of the in-sample one-step naive forecast. It was proposed in 2005 by statistician [[Rob J. Hyndman]] and Professor of Decision Sciences Anne B. Koehler, who described it as a "generally applicable measurement of forecast accuracy without the problems seen in the other measurements."&lt;ref name="Hyndman2006a" /&gt; The mean absolute scaled error has favorable properties when compared to other methods for calculating [[forecast error]]s, such as [[Root-mean-square error|root-mean-square-deviation]], and is therefore recommended for determining comparative accuracy of forecasts.&lt;ref name=":1"&gt;{{Cite journal|last=Franses|first=Philip Hans|date=2016-01-01|title=A note on the Mean Absolute Scaled Error|journal=International Journal of Forecasting|volume=32|issue=1|pages=20–22|doi=10.1016/j.ijforecast.2015.03.008|url=http://repub.eur.nl/pub/78815}}&lt;/ref&gt;

== Rationale ==
The mean absolute scaled error has the following desirable properties:&lt;ref name="Hyndman2006" /&gt;
# '''[[Scale invariance]]''': The mean absolute scaled error is independent of the scale of the data, so can be used to compare forecasts across data sets with different scales.
# '''Predictable behavior as &lt;math&gt;y_{t} \rightarrow 0&lt;/math&gt; :''' Percentage forecast accuracy measures such as the [[Mean absolute percentage error]] (MAPE) rely on division of &lt;math&gt;y_{t}&lt;/math&gt;, skewing the distribution of the MAPE for values of &lt;math&gt;y_{t}&lt;/math&gt; near or equal to 0. This is especially problematic for data sets whose scales do not have a meaningful 0, such as temperature in Celsius or Fahrenheit, and for intermittent demand data sets, where &lt;math&gt;y_{t} = 0&lt;/math&gt; occurs frequently. 
# '''Symmetry:''' The mean absolute scaled error penalizes positive and negative forecast errors equally, and penalizes errors in large forecasts and small forecasts equally. In contrast, the MAPE and median absolute percentage error (MdAPE) fail both of these criteria, while the "symmetric" sMAPE and sMdAPE&lt;ref&gt;{{Cite journal|last=Makridakis|first=Spyros|date=1993-12-01|title=Accuracy measures: theoretical and practical concerns|journal=International Journal of Forecasting|volume=9|issue=4|pages=527–529|doi=10.1016/0169-2070(93)90079-3}}&lt;/ref&gt; fail the second criterion.
# '''Interpretability:''' The mean absolute scaled error can be easily interpreted, as values greater than one indicate that in-sample one-step forecasts from the naïve method perform better than the forecast values under consideration.
# '''Asymptotic normality of the MASE:''' The Diebold-Mariano test for one-step forecasts is used to test the statistical significance of the difference between two sets of forecasts.&lt;ref&gt;{{Cite journal|last=Diebold|first=Francis X.|last2=Mariano|first2=Roberto S.|date=1995|title=Comparing predictive accuracy|url=|journal=Journal of Business and Economic Statistics|volume=13|issue=3|pages=253–263|doi=10.1080/07350015.1995.10524599}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Diebold|first=Francis X.|last2=Mariano|first2=Roberto S.|date=2002|title=Comparing predictive accuracy|url=|journal=Journal of Business and Economic Statistics|volume=20|issue=1|pages=134–144|doi=10.1198/073500102753410444}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Diebold|first=Francis X.|date=2015|title=Comparing predictive accuracy, twenty years later: A personal perspective on the use and abuse of Diebold–Mariano tests|url=http://www.nber.org/papers/w18391.pdf|journal=Journal of Business and Economic Statistics|volume=33|issue=1|pages=1|doi=10.1080/07350015.2014.983236}}&lt;/ref&gt; To perform hypothesis testing with the Diebold-Mariano test statistic, it is desirable for &lt;math&gt;DM \sim N(0,1)&lt;/math&gt;, where &lt;math&gt;DM&lt;/math&gt; is the value of the test statistic. The DM statistic for the MASE has been empirically shown to approximate this distribution, while the mean relative absolute error (MRAE), MAPE and sMAPE do not.&lt;ref name=":1" /&gt;


== Non seasonal time series ==
For a non-seasonal time series,&lt;ref name=":0"/&gt; the mean absolute scaled error is estimated by 
: &lt;math&gt;\mathrm{MASE} = \mathrm{mean}\left( \frac{\left| e_j \right|}{\frac{1}{T-1}\sum_{t=2}^T \left| Y_t-Y_{t-1}\right|} \right) = \frac{\frac{1}{J}\sum_{j}\left| e_j \right|}{\frac{1}{T-1}\sum_{t=2}^T \left| Y_t-Y_{t-1}\right|}&lt;/math&gt;&lt;ref name="Hyndman2006" /&gt;
where the numerator ''e''&lt;sub&gt;''j''&lt;/sub&gt; is the [[forecast error]] for a given period (with ''J'', the number of forecasts), defined as the actual value (''Y''&lt;sub&gt;''j''&lt;/sub&gt;) minus the forecast value (''F''&lt;sub&gt;''j''&lt;/sub&gt;) for that period: ''e''&lt;sub&gt;''j''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''Y''&lt;sub&gt;''j''&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''F''&lt;sub&gt;''j''&lt;/sub&gt;, and the denominator is the [[mean absolute error]] of the one-step "[[Forecasting#Na.C3.AFve approach|naive forecast method]]" on the training set (here defined as ''t = 1..n''),&lt;ref name=":0"&gt;{{Cite web|url=https://www.otexts.org/fpp/2/5|title=2.5 Evaluating forecast accuracy {{!}} OTexts|website=www.otexts.org|access-date=2016-05-15}}&lt;/ref&gt; which uses the actual value from the prior period as the forecast: ''F''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''Y''&lt;sub&gt;''t''−1&lt;/sub&gt;&lt;ref name="Hyndman2008" /&gt;

== Seasonal time series ==
For a seasonal time series, the mean absolute scaled error is estimated in a manner similar to the method for non-seasonal time series:

&lt;math&gt;    \mathrm{MASE} = \mathrm{mean}\left( \frac{\left| e_j \right|}{\frac{1}{T-m}\sum_{t=m+1}^T \left| Y_t-Y_{t-m}\right|} \right) = \frac{\frac{1}{J}\sum_{j} \left| e_j \right|}{\frac{1}{T-m}\sum_{t=m+1}^T \left| Y_t-Y_{t-m}\right|}&lt;/math&gt;&lt;ref name=":0"/&gt;

The main difference with the method for non-seasonal time series, is that the denominator is the [[mean absolute error]] of the one-step "[[Forecasting|seasonal naive forecast method]]" on the training set,&lt;ref name=":0" /&gt; which uses the actual value from the prior season as the forecast: ''F''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''Y''&lt;sub&gt;''t''−m&lt;/sub&gt;,&lt;ref name="Hyndman2008" /&gt; where m is the seasonal period.

This [[wikt:scalefree|scale-free]] error metric "can be used to compare forecast methods on a single series and also to compare forecast accuracy between series. This metric is well suited to intermittent-demand series{{clarify|what is an intermittent-demand series?|date=April 2011}} because it never gives infinite or undefined values&lt;ref name="Hyndman2006a" /&gt; except in the irrelevant case where all historical data are equal.&lt;ref name="Hyndman2006" /&gt;

When comparing forecasting methods, the method with the lowest MASE is the preferred method.

==See also==
* [[Mean squared error]]
* [[Mean absolute error]]
* [[Mean absolute percentage error]]
* [[Root-mean-square deviation]]
* [[Test set]]

==References==
{{Reflist|refs=
&lt;ref name="Hyndman2006"&gt;Hyndman, R. J. and Koehler A. B. (2006). "Another look at measures of forecast accuracy." ''International Journal of Forecasting'' volume 22 issue 4, pages 679-688. {{doi|10.1016/j.ijforecast.2006.03.001}}&lt;/ref&gt;
&lt;ref name="Hyndman2006a"&gt;Hyndman, R. J. (2006). "Another look at measures of forecast accuracy", FORESIGHT Issue 4 June 2006, pg46 [http://robjhyndman.com/papers/foresight.pdf]&lt;/ref&gt;
&lt;ref name="Hyndman2008"&gt;Hyndman, Rob et al, ''Forecasting with Exponential Smoothing:  The State Space Approach'', Berlin:  Springer-Verlag, 2008.  {{ISBN|978-3-540-71916-8}}.&lt;/ref&gt;
}}

{{DEFAULTSORT:Mean absolute scaled error}}
[[Category:Point estimation performance]]
[[Category:Statistical deviation and dispersion]]
[[Category:Time series]]</text>
      <sha1>nfnnn9ihntuevbjnirw6wiw0q7v4h5x</sha1>
    </revision>
  </page>
</mediawiki>
